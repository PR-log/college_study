상관관계는 -1~ 1까지인데 0에 가까울수록 관계가 없다, -는 음의 상관관계, +는 양의 상관관계이다   

https://colab.research.google.com/github/rickiepark/handson-ml3/blob/main/02_end_to_end_machine_learning_project.ipynb#scrollTo=b93v8op3oyiN


```
from pandas.plotting import scatter_matrix
attributes = ["median_house_value", "median_income", "total_rooms",
              "housing_median_age"]
scatter_matrix(housing[attributes], figsize=(12, 8))
save_fig("scatter_matrix_plot")  # 추가 코드
plt.show()
```
<img width="1178" height="777" alt="image" src="https://github.com/user-attachments/assets/38acf0b2-85d0-4e03-8d04-965ce16862f8" />

scatter plot을 했을 떄 어떤 모양이 상관이 높은지 바로 파악이 가능해야 함

<img width="1375" height="1122" alt="image" src="https://github.com/user-attachments/assets/14efdfa9-2566-47ab-b958-922f00a27c01" />

<img width="921" height="427" alt="image" src="https://github.com/user-attachments/assets/e0ba453a-2301-4746-a201-0218e82951a8" />
x에 대한 y의 변화의 경향 파악해야함

대부분의 경우 한번에 상관관계가 보이지 않아서 데이터에 작업이 필요하다
>>> 특성 조합

```
housing["rooms_per_house"] = housing["total_rooms"] / housing["households"]
housing["bedrooms_ratio"] = housing["total_bedrooms"] / housing["total_rooms"]
housing["people_per_house"] = housing["population"] / housing["households"]
```
새로운 특성조합 생성

>>> 반복적인 과정이다
여러개 조합을 만들어가면서 적합한 특성을 찾아가야한다


<img width="628" height="825" alt="image" src="https://github.com/user-attachments/assets/b7e3b62d-6187-4eac-be70-fcaf78249875" />

훈련셋으로 분리한 세트
```
housing = strat_train_set.drop("median_house_value", axis=1)
#괄호안의 변수를 버림
housing_labels = strat_train_set["median_house_value"].copy()
```

비어있는 데이터 처리
```
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy="median")
```
무책임하게 평균값으로 채우는 방법

```
imputer.fit(housing_num)
```

```
imputer.statistics_
```
>>> array([-118.51  ,   34.26  ,   29.    , 2125.    ,  434.    , 1167.    ,
        408.    ,    3.5385])
>>>

훈련 세트 변환
```
X = imputer.transform(housing_num)
imputer.feature_names_in_
housing_tr = pd.DataFrame(X, columns=housing_num.columns,
                          index=housing_num.index)
housing_tr.loc[null_rows_idx].head()
```

만약 특성 여러개가 비어있어도 imputer을 사용해도 된다
왜냐하면 inputer은 이미 모든 특성의 값을 다 가져왔기 때문,
선택해서 집어넣는것 뿐, 이미 비어있는 모든 값을 다 가져왔음

inputer 설정 확인
```
inputer.strategy
'''

### 텍스트와 범주형 특성 다루기
인코딩(encoding)
* 정보를 특정 형식으로 변환하는 과정(~화, 코드화, 암호화)

ordinalEncoder 코드를 순차적으로 숫자로 변환
```
from sklearn.preprocessing import OrdinalEncoder

ordinal_encoder = OrdinalEncoder()
housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)
housing_cat_encoded[:8]
```
>>> array([[3.],
       [0.],
       [1.],
       [1.],
       [4.],
       [1.],
       [0.],
       [3.]])

```
ordinal_encoder.categories_
```
>>> [array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],
       dtype=object)]
```

그러나 숫자 자체가 의미를 가지지 않기 때문에
### one-hot encoder을 사용
* 중요
머신러닝에 거의 무조건 사용

카테고리 여러가지가 있을 때
예) 서울, 대전, 대구, 부산
한 특성 서울은 1(핫) 이고
나머지는 0으로 처리

장점
- 카테고리를 의미있게 해준다
단점
- 데이터 크기가 매우 커진다(희소 행렬)

특성이 영향을 주는지 안주는지 확인 가능하도록 만드는것

더미변수
- 원 핫 처리로 만들어진 컬럼들

- 더미변수처리는 시험에 일단 안나옴

### 특성 스케일링
특성의 스케일이 너무 크면 스케일을 낮추는것






